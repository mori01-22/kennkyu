{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mori01-22/kennkyu/blob/main/Sample1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rpFayR-e_vXL"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/mori01-22/kennkyu/blob/main/Sample1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "\n",
    "# タンス検出 (二値分類) ノートブック\n",
    "\n",
    "このノートブックは、与えられた画像（タンスあり / タンスなし）を識別するための学習・評価・推論パイプラインを示します。主に TensorFlow / Keras の転移学習（MobileNetV2）を利用します。\n",
    "\n",
    "前提: 画像データはローカルに用意され、以下のようなフォルダ構成になっていることを想定します:\n",
    "\n",
    "```\n",
    "data/\n",
    "  train/\n",
    "    tansu/        # タンスが写っている画像（約1000枚程度）\n",
    "    not_tansu/    # タンスが写っていない画像\n",
    "```\n",
    "\n",
    "(検証は自動で分割します)\n",
    "\n",
    "ノート: このノートブックは Colab / ローカルどちらでも動きます。ローカル環境で GPU を使う場合は適切に TensorFlow をインストールしてください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T_Pe8NIw_vXO",
    "outputId": "ca165ff2-6757-4dd7-9527-809649509dd1"
   },
   "outputs": [],
   "source": [
    "# 基本的なインポートと設定\n",
    "import os\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print('TensorFlow version:', tf.__version__)\n",
    "\n",
    "# 再現性のためのシード設定（任意）\n",
    "SEED = 123\n",
    "tf.random.set_seed(SEED)\n",
    "np.random.seed(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 設定: モデル保存先を明示的に切り替えられるようにするセル\n",
    "# 注意: 自動で Drive をマウントするとブロッキングしてノートブックが応答しなくなることがあります。\n",
    "# 必要なら手動でマウントしてから保存してください。\n",
    "\n",
    "# True にすると Drive 配下に保存を試みる（ただし自動マウントは行いません）\n",
    "SAVE_TO_DRIVE = False\n",
    "# プロジェクト直下に保存を試みる場合は True\n",
    "SAVE_TO_PROJECT_ROOT = True\n",
    "# Drive 内のフォルダ（プロジェクト直下が見つからない場合のフォールバック）\n",
    "DRIVE_SUBDIR = 'kennkyu_models'\n",
    "# 明示的に絶対パスを指定したい場合はそれを使います（空文字列で無効）\n",
    "FORCE_SAVE_PATH = ''\n",
    "\n",
    "\n",
    "def find_project_root_by_git(start_dir=None, max_up=6):\n",
    "    \"\"\"Walk up from start_dir looking for a .git folder to identify repo root.\"\"\"\n",
    "    import os\n",
    "    if start_dir is None:\n",
    "        start_dir = os.getcwd()\n",
    "    cur = os.path.abspath(start_dir)\n",
    "    for _ in range(max_up):\n",
    "        if os.path.isdir(os.path.join(cur, '.git')):\n",
    "            return cur\n",
    "        parent = os.path.dirname(cur)\n",
    "        if parent == cur:\n",
    "            break\n",
    "        cur = parent\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_repo_in_drive_by_name(repo_name):\n",
    "    import os\n",
    "    base = '/content/drive/MyDrive'\n",
    "    if os.path.isdir(base):\n",
    "        candidate = os.path.join(base, repo_name)\n",
    "        if os.path.isdir(candidate):\n",
    "            return candidate\n",
    "    return None\n",
    "\n",
    "\n",
    "def get_save_path(fname='tansu_detector.keras'):\n",
    "    import os\n",
    "    # 1) FORCE_SAVE_PATH が指定されていればそれを使う\n",
    "    if FORCE_SAVE_PATH:\n",
    "        return FORCE_SAVE_PATH\n",
    "\n",
    "    # 2) まずプロジェクト直下保存を試みる（.git が見つかればそこをルートとみなす）\n",
    "    if SAVE_TO_PROJECT_ROOT:\n",
    "        proj_root = find_project_root_by_git()\n",
    "        if proj_root and os.access(proj_root, os.W_OK):\n",
    "            return os.path.join(proj_root, fname)\n",
    "\n",
    "    # 3) Colab 判定（google.colab が存在するか、/content が存在するか）\n",
    "    try:\n",
    "        shell = str(get_ipython())\n",
    "        is_colab = 'google.colab' in shell or os.path.exists('/content')\n",
    "    except Exception:\n",
    "        is_colab = os.path.exists('/content')\n",
    "\n",
    "    # 4) Colab + DRIVE 保存を選んだ場合: Drive が既にマウントされているか確認して保存\n",
    "    if SAVE_TO_DRIVE and is_colab:\n",
    "        # NOTE: do NOT call drive.mount() automatically (it can block in some environments).\n",
    "        drive_base = '/content/drive'\n",
    "        if os.path.isdir(drive_base):\n",
    "            # Try to locate a folder in Drive with same repo name\n",
    "            repo_name = os.path.basename(os.getcwd())\n",
    "            drive_repo = find_repo_in_drive_by_name(repo_name)\n",
    "            if drive_repo and os.access(drive_repo, os.W_OK):\n",
    "                return os.path.join(drive_repo, fname)\n",
    "            # fallback: use a dedicated folder in Drive\n",
    "            drive_folder = os.path.join(drive_base, 'MyDrive', DRIVE_SUBDIR)\n",
    "            os.makedirs(drive_folder, exist_ok=True)\n",
    "            return os.path.join(drive_folder, fname)\n",
    "        else:\n",
    "            # Drive not mounted; return a clear path in /content and warn the user\n",
    "            tmp_path = os.path.join('/content', fname)\n",
    "            print('WARNING: SAVE_TO_DRIVE=True but /content/drive not mounted.\\nPlease mount Drive manually in Colab (or set SAVE_TO_DRIVE=False). Using temporary path:', tmp_path)\n",
    "            return tmp_path\n",
    "\n",
    "    # 5) デフォルト: カレントディレクトリ\n",
    "    return os.path.join(os.getcwd(), fname)\n",
    "\n",
    "print('Save config: SAVE_TO_DRIVE=', SAVE_TO_DRIVE,\n",
    "      'SAVE_TO_PROJECT_ROOT=', SAVE_TO_PROJECT_ROOT,\n",
    "      'DRIVE_SUBDIR=', DRIVE_SUBDIR,\n",
    "      'FORCE_SAVE_PATH=', bool(FORCE_SAVE_PATH))\n",
    "print('Example save path:', get_save_path())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jtOAcIWf_vXP",
    "outputId": "8925f8bd-e905-4401-cc3e-f705b5132edd"
   },
   "outputs": [],
   "source": [
    "# データセットのパスとパラメータ（必要に応じて変更）\n",
    "data_dir = Path('data/demo_train')  # ここに tansu と not_tansu のフォルダがある想定\n",
    "# 学習や推論の説明を簡単にするため、標準的なサイズに戻します\n",
    "img_size = (224, 224)\n",
    "batch_size = 32\n",
    "\n",
    "# ヘルパ: デモ用の簡易画像データを生成（data/demo_train に作成）\n",
    "def create_demo_data(base_dir, img_size=(224,224), n_per_class=12):\n",
    "    from PIL import Image, ImageDraw\n",
    "    base = Path(base_dir)\n",
    "    (base / 'tansu').mkdir(parents=True, exist_ok=True)\n",
    "    (base / 'not_tansu').mkdir(parents=True, exist_ok=True)\n",
    "    w, h = img_size\n",
    "    for i in range(n_per_class):\n",
    "        img = Image.new('RGB', (w, h), color=(150, 120, 90))\n",
    "        d = ImageDraw.Draw(img)\n",
    "        d.rectangle([int(w*0.2), int(h*0.2), int(w*0.8), int(h*0.9)], fill=(80, 60, 40))\n",
    "        img.save(base / 'tansu' / f'tansu_{i}.jpg', 'JPEG')\n",
    "        img2 = Image.new('RGB', (w, h), color=(200, 220, 240))\n",
    "        d2 = ImageDraw.Draw(img2)\n",
    "        d2.ellipse([int(w*0.3), int(h*0.3), int(w*0.7), int(h*0.7)], fill=(120, 140, 160))\n",
    "        img2.save(base / 'not_tansu' / f'not_{i}.jpg', 'JPEG')\n",
    "    print(f'Created demo dataset at: {base.resolve()} (each class: {n_per_class} images)')\n",
    "\n",
    "# フォルダ存在確認・デモ作成（不足時）\n",
    "if not data_dir.exists() or not any(p.is_dir() for p in data_dir.iterdir()):\n",
    "    print('data/train が見つからないため、デモ用データを生成します。')\n",
    "    demo_dir = Path('data/demo_train')\n",
    "    if not demo_dir.exists() or not any(p.is_dir() for p in demo_dir.iterdir()):\n",
    "        create_demo_data(demo_dir, img_size=img_size, n_per_class=12)\n",
    "    data_dir = demo_dir\n",
    "\n",
    "# データ読み込み (80% training, 20% validation)\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=SEED,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "    data_dir,\n",
    "    labels='inferred',\n",
    "    label_mode='binary',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=SEED,\n",
    "    image_size=img_size,\n",
    "    batch_size=batch_size,\n",
    ")\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print('Classes:', class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "id": "xXhVs2BR_vXQ",
    "outputId": "4debde22-bf6f-49ac-8b7a-e8d485d45e7e"
   },
   "outputs": [],
   "source": [
    "# パフォーマンス最適化: キャッシュとプリフェッチ\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# サンプル画像を表示して確認\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "for images, labels in train_ds.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3,3,i+1)\n",
    "        plt.imshow(images[i].numpy().astype('uint8'))\n",
    "        plt.title(class_names[int(labels[i])])\n",
    "        plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "N_JfJyTD_vXS",
    "outputId": "62d011ce-835a-4b77-d1c7-0bbd84d61b3b"
   },
   "outputs": [],
   "source": [
    "# シンプルなモデル構築（理解しやすく最小構成）\n",
    "# 1) 軽いデータ拡張\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip('horizontal'),\n",
    "    layers.RandomRotation(0.06),\n",
    "], name='data_augmentation')\n",
    "\n",
    "# 2) バックボーン: EfficientNetB0 を優先、なければ MobileNetV2\n",
    "try:\n",
    "    base_model = tf.keras.applications.EfficientNetB0(\n",
    "        input_shape=img_size + (3,), include_top=False, weights='imagenet')\n",
    "    from tensorflow.keras.applications.efficientnet import preprocess_input as preprocess_input\n",
    "    print('Using EfficientNetB0')\n",
    "except Exception:\n",
    "    base_model = tf.keras.applications.MobileNetV2(\n",
    "        input_shape=img_size + (3,), include_top=False, weights='imagenet')\n",
    "    from tensorflow.keras.applications.mobilenet_v2 import preprocess_input as preprocess_input\n",
    "    print('Using MobileNetV2')\n",
    "\n",
    "base_model.trainable = False  # まずはバックボーンを凍結してヘッドだけ学習\n",
    "\n",
    "# 3) 簡単なヘッド\n",
    "inputs = keras.Input(shape=img_size + (3,))\n",
    "x = data_augmentation(inputs)\n",
    "x = preprocess_input(x)\n",
    "x = base_model(x, training=False)\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "\n",
    "# 4) コンパイル（シンプルに BCE と Adam）\n",
    "model.compile(optimizer=keras.optimizers.Adam(1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# シンプルな学習セル: 最小限のコールバックで学習\n",
    "callbacks = [\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True),\n",
    "    keras.callbacks.ModelCheckpoint('best_tansu_model.h5', save_best_only=True)\n",
    "]\n",
    "\n",
    "# 少数エポックから始めて様子を見る（実データで本気で学習する場合は増やす）\n",
    "epochs = 10\n",
    "\n",
    "history = model.fit(train_ds, validation_data=val_ds, epochs=epochs, callbacks=callbacks)\n",
    "\n",
    "# NOTE: モデルの最良重みは 'best_tansu_model.h5' に保存されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2vcRiex_vXT",
    "outputId": "733887c2-8b4f-4341-a46a-0bcdd82db9b9"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "save_fname = 'tansu_detector.keras'\n",
    "# ローカル（カレントディレクトリ）に保存します\n",
    "save_path = os.path.join(os.getcwd(), save_fname)\n",
    "try:\n",
    "    model.save(save_path)\n",
    "    print('モデルを保存しました:', save_path)\n",
    "except Exception as e:\n",
    "    print('モデル保存に失敗しました:', e)\n",
    "    # フォールバックで .h5 形式で保存を試みる\n",
    "    try:\n",
    "        fallback = os.path.join(os.getcwd(), 'best_tansu_model.h5')\n",
    "        model.save(fallback)\n",
    "        print('Fallback: モデルを保存しました:', fallback)\n",
    "    except Exception as e2:\n",
    "        print('Fallback 保存も失敗しました:', e2)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
